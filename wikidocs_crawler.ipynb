{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wickdocs = requests.get(\"https://wikidocs.net/book/2788\")\n",
    "soup = bs(wickdocs.text, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00. 파이토치 공식 문서 링크 https://wikidocs.net/53383\n",
      "01. 책 소개하기 https://wikidocs.net/32471\n",
      "02. 파이토치 기초(PyTorch Basic) https://wikidocs.net/52415\n",
      "\t01. 파이토치 패키지의 기본 구성 https://wikidocs.net/57168\n",
      "\t02. 텐서 조작하기(Tensor Manipulation) 1 https://wikidocs.net/52460\n",
      "\t03. 텐서 조작하기(Tensor Manipulation) 2 https://wikidocs.net/52846\n",
      "\t04. 파이썬 클래스(class) https://wikidocs.net/60034\n",
      "03. 선형 회귀(Linear Regression) https://wikidocs.net/53545\n",
      "\t01. 선형 회귀(Linear Regression) https://wikidocs.net/53560\n",
      "\t02. 자동 미분(Autograd) https://wikidocs.net/60754\n",
      "\t03. 다중 선형 회귀(Multivariable Linear regression) https://wikidocs.net/54841\n",
      "\t04. nn.Module로 구현하는 선형 회귀 https://wikidocs.net/55409\n",
      "\t05. 클래스로 파이토치 모델 구현하기 https://wikidocs.net/60036\n",
      "\t06. 미니 배치와 데이터 로드(Mini Batch and Data Load) https://wikidocs.net/55580\n",
      "\t07. 커스텀 데이터셋(Custom Dataset) https://wikidocs.net/57165\n",
      "04. 로지스틱 회귀(Logistic Regression) https://wikidocs.net/57810\n",
      "\t01. 로지스틱 회귀(Logistic Regression) https://wikidocs.net/57805\n",
      "\t02. nn.Module로 구현하는 로지스틱 회귀 https://wikidocs.net/58686\n",
      "\t03. 클래스로 파이토치 모델 구현하기 https://wikidocs.net/60037\n",
      "05. 소프트맥스 회귀(Softmax Regression) https://wikidocs.net/59425\n",
      "\t01. 원-핫 인코딩(One-Hot Encoding) https://wikidocs.net/59678\n",
      "\t02. 소프트맥스 회귀(Softmax Regression) 이해하기 https://wikidocs.net/59427\n",
      "\t03. 소프트맥스 회귀의 비용 함수 구현하기 https://wikidocs.net/60572\n",
      "\t04. 소프트맥스 회귀 구현하기 https://wikidocs.net/60575\n",
      "\t05. 소프트맥스 회귀로 MNIST 데이터 분류하기 https://wikidocs.net/60324\n",
      "06. 인공 신경망(Aritificial Neural Network) https://wikidocs.net/60002\n",
      "\t01. 머신 러닝 용어 이해하기 https://wikidocs.net/60021\n",
      "\t02. 퍼셉트론(Perceptron) https://wikidocs.net/60680\n",
      "\t03. XOR 문제 - 단층 퍼셉트론 구현하기 https://wikidocs.net/60848\n",
      "\t04. 역전파(BackPropagation) https://wikidocs.net/60682\n",
      "\t05. XOR 문제 - 다층 퍼셉트론 구현하기 https://wikidocs.net/61010\n",
      "\t06. 비선형 활성화 함수(Activation function) https://wikidocs.net/60683\n",
      "\t07. 다층 퍼셉트론으로 손글씨 분류하기 https://wikidocs.net/61046\n",
      "\t08. 다층 퍼셉트론으로 MNIST 분류하기 https://wikidocs.net/61073\n",
      "\t09. 과적합(Overfitting)을 막는 방법들 https://wikidocs.net/60751\n",
      "\t10. 기울기 소실(Gradient Vanishing)과 폭주(Exploding) https://wikidocs.net/61271\n",
      "07. 합성곱 신경망(Convolutional Neural Network) https://wikidocs.net/62304\n",
      "\t01. 합성곱과 풀링(Convolution and Pooling) https://wikidocs.net/62306\n",
      "\t02. CNN으로 MNIST 분류하기 https://wikidocs.net/63565\n",
      "\t03. 깊은 CNN으로 MNIST 분류하기 https://wikidocs.net/63618\n",
      "08. 자연어 처리의 전처리 https://wikidocs.net/64515\n",
      "\t01. 자연어 처리 전처리 이해하기 https://wikidocs.net/64517\n",
      "\t02. 토치텍스트 튜토리얼(Torchtext tutorial) - 영어 https://wikidocs.net/60314\n",
      "\t03. 토치텍스트 튜토리얼(Torchtext tutorial) - 한국어 https://wikidocs.net/65348\n",
      "\t04. 토치텍스트(TorchText)의 batch_first https://wikidocs.net/65794\n",
      "09. 단어의 표현 방법 https://wikidocs.net/60851\n",
      "\t01. NLP에서의 원-핫 인코딩(One-hot encoding) https://wikidocs.net/60853\n",
      "\t02. 워드 임베딩(Word Embedding) https://wikidocs.net/60852\n",
      "\t03. 워드투벡터(Word2Vec) https://wikidocs.net/60854\n",
      "\t05. 임베딩 벡터의 시각화(Embedding Visualization) https://wikidocs.net/60856\n",
      "\t06. 글로브(GloVe) https://wikidocs.net/60858\n",
      "\t07. 파이토치(PyTorch)의 nn.Embedding() https://wikidocs.net/64779\n",
      "\t08. 사전 훈련된 워드 임베딩(Pretrained Word Embedding) https://wikidocs.net/64904\n",
      "10. 순환 신경망(Recurrent Neural Network) https://wikidocs.net/60760\n",
      "\t01. 순환 신경망(Recurrent Neural Network, RNN) https://wikidocs.net/60690\n",
      "\t02. 장단기 메모리(Long Short-Term Memory, LSTM) https://wikidocs.net/60762\n",
      "11. 다대다 RNN을 이용한 텍스트 생성 https://wikidocs.net/64736\n",
      "\t01. 문자 단위 RNN(Char RNN) https://wikidocs.net/64703\n",
      "\t02. 문자 단위 RNN(Char RNN) - 더 많은 데이터 https://wikidocs.net/64739\n",
      "\t03. 단어 단위 RNN - 임베딩 사용 https://wikidocs.net/64765\n",
      "12. 다대일 RNN을 이용한 텍스트 분류 https://wikidocs.net/64737\n",
      "\t01. 파이토치를 이용한 텍스트 분류(Text classification using PyTorch) https://wikidocs.net/66115\n",
      "\t02. IMDB 리뷰 감성 분류하기(IMDB Movie Review Sentiment Analysis) https://wikidocs.net/60691\n",
      "13. 시퀀스 레이블링(Sequence Labeling) https://wikidocs.net/66107\n",
      "\t01. 시퀀스 레이블링(Sequence Labeling) https://wikidocs.net/66108\n",
      "\t02. 양방향 RNN을 이용한 품사 태깅 https://wikidocs.net/66747\n",
      "14. 시퀀스투시퀀스(Sequence-to-Sequence, seq2seq) https://wikidocs.net/64783\n",
      "\t01. 시퀀스투시퀀스(Sequence-to-Sequence, seq2seq) https://wikidocs.net/65154\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "elements = soup.select('div.list-group.list-group-toc a')\n",
    "\n",
    "for index, element in enumerate(elements):\n",
    "        if index == 0: continue\n",
    "        title= element.span.attrs['title']\n",
    "        href = element.attrs['href']\n",
    "\n",
    "        ele = soup.select('div.list-group.list-group-toc a >span>span')\n",
    "        padd = ele[index-1].attrs['style']\n",
    "        if '20' in padd:\n",
    "                title='\\t'+title\n",
    "        hr = re.findall(\"\\(([^)]+)\",href)[0]\n",
    "        print(f\"{title} https://wikidocs.net/{hr}\")\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4b005c880547f9bbb67cf8f41af471452011e749f598c1e52c7147016c653df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
